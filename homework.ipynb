{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework â„–2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework will be dedicated to **ASR & Co**.\n",
    "\n",
    "In general, you may implement any ASR model that was discussed in the lecture,\n",
    "but we recommend to implement **QuartzNet**.\n",
    "\n",
    "## **Important aspects (model)**\n",
    "1) Pay attention on different length of utterances. P.S. **masking**.\n",
    "    \n",
    "2) A good ASR is a robust ASR, so we ask you to implement and use at least **4 types of augmentations** (P.S. 2 seminar).\n",
    "\n",
    "3) Also, to get better quality, we ask you to implement a **beam search** for better decoding.\n",
    "\n",
    "4) (Bonus) As a bonus you can use **BPE** instead of Char. You can use SentencePiece, HuggingFace or YouTokenToMe.\n",
    "\n",
    "5) (Bonus) As a bonus you can take pretrained **LM** (or train yourself) and fusing LM with ASR.\n",
    "    Way of fusing you may choose yourself.\n",
    "\n",
    "## **Important aspects (code)**\n",
    "1) You already know about pytorch-lighting (I hope :)) but you are not allowed to use it in this homework.\n",
    "\n",
    "2) Try to write code more structurally and cleanly !\n",
    "\n",
    "3) Good logging of experiments save your nerves and time,\n",
    "    so we ask you to use **W&B** and log at least loss, WER, CER and pairs (audio -- recognized text).\n",
    "    **Do not remove** the logs until we have checked your work and given you a grade!\n",
    "\n",
    "4) We also ask you to organize your code in github repo with Docker and setup.py. You can use my template https://github.com/markovka17/dl-start-pack.\n",
    "\n",
    "5) Your work **must be** reproducable, so fix seed, save the weights of model, and etc.\n",
    "\n",
    "6) In the end of your work write inference utils. Anyone should be able to take your weight, load it into the model and run it on some audio track.\n",
    "\n",
    "## Data\n",
    "\n",
    "1) If you have enough GPU and CPU we recommend to train model on librispeech-100 (100 hours).\n",
    "    If you poor student your choise is LJSpeech (24 housr) :)\n",
    "\n",
    "1.1) LJSpeech https://keithito.com/LJ-Speech-Dataset/. Note that audio file is a single-channel 16-bit PCM WAV with a sample rate of 22050 Hz. So, feel free to resample audio in 16000 Hz.\n",
    "    Target text is **Normalized Transcription** in **transcripts.csv**.\n",
    "\n",
    "1.2) LibriSpeech https://www.openslr.org/12. Download and use train-clean-100.tar.gz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
